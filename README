# ML_LIBRARY

A lightweight Python library implementing classic machine learning algorithms **from scratch** using NumPy.  
Designed for learning, experimentation, and building intuition behind core ML models.

---

##  Features Implemented

- Principal Component Analysis (PCA)  
- Fisher’s Discriminant Analysis (FDA – Multi-class)  
- Linear Discriminant Analysis (LDA)  
- Quadratic Discriminant Analysis (QDA)  
- Polynomial Regression (Closed-form OLS)  
- AdaBoost (with Decision Stumps)  
- Gradient Boosting (with Decision Stumps, squared & absolute loss)  
- Basic Neural Network Utilities (forward & backward pass)  

---

##  Installation

Clone the repository and install locally:

```bash
git clone https://github.com/Saksham355/ml_library.git
cd ml_tools
pip install -e .
```

### PCA - Principal Component Analysis
-------------------------------------------
Reduces dimensionality of data by projecting onto top eigenvectors.

```python
import numpy as np
from ml_tools.preprocessing import pca

X = np.random.rand(100, 5)
X_pca = pca(X, num_features=2)

print("Original shape:", X.shape)
print("Reduced shape:", X_pca.shape)
```
### Fisher’s Discriminant Analysis (FDA)
-------------------------------------------
Finds projection maximizing class separation in multi-class data.

```python
import numpy as np
from ml_tools.discriminant import fda

X = np.array([[2,3],[3,3],[2,4],[7,8],[8,9],[9,8]])
y = np.array([0,0,0,1,1,1])

X_proj, w = fda(X, y)

print("Projection vector:\n", w)
print("Projected data:\n", X_proj[:5])
```
### Linear Discriminant Analysis (LDA)
-------------------------------------------
Learns shared covariance and class means to classify with linear boundaries.

```python
import numpy as np
from ml_tools.discriminant import lda_train, lda_predict

X = np.random.rand(20, 3)
y = np.array([0]*10 + [1]*10)

u, s = lda_train(X, y)
y_pred = lda_predict(X, u, s)

print("Predictions:", y_pred)
```
### Quadratic Discriminant Analysis (QDA)
-------------------------------------------
Each class has its own covariance matrix, enabling quadratic decision boundaries.

```python
import numpy as np
from ml_tools.discriminant import qda_train, qda_predict

X = np.random.rand(20, 3)
y = np.array([0]*10 + [1]*10)

u, s = qda_train(X, y)
y_pred = qda_predict(X, u, s)

print("Predictions:", y_pred)
```
### AdaBoost (Decision Stumps)
-------------------------------------------
Boosting with weak learners to improve classification accuracy.
```python
import numpy as np
from ml_tools.boosting import bestStump, adaboost_predict

X = np.array([[1],[2],[3],[4],[5]])
y = np.array([-1, -1, 1, 1, 1])

weights = np.ones(len(y)) / len(y)
stump, threshold, error = bestStump(X, y, weights)
print("Best stump:", stump, "Threshold:", threshold, "Error:", error)

classifiers = [(stump, threshold)]
alphas = [1.0]
preds = adaboost_predict(X, classifiers, alphas)

print("Predictions:", preds)
```
### Gradient Boosting
-------------------------------------------
Sequentially fits weak learners on residuals to minimize loss.
```python
import numpy as np
from ml_tools.boosting import gradient_boosting

x_train = np.linspace(0, 1, 50)
y_train = np.sin(2*np.pi*x_train)

x_test = np.linspace(0, 1, 20)
y_test = np.sin(2*np.pi*x_test)

_, _, train_loss, test_loss = gradient_boosting(
    x_train, y_train, x_test, y_test,
    loss="squared", lr=0.1, iterations=50
)

print("Final Train Loss:", train_loss[-1])
print("Final Test Loss:", test_loss[-1])
```
### Neural Network Utilities
-------------------------------------------
Implements forward and backward pass for a 1-hidden-layer NN.
```python
import numpy as np
from ml_tools.neural_net_utils import sigmoid, forward_pass, backward_pass

W1, b1 = np.random.randn(2, 2), np.random.randn(2)
W2, b2 = np.random.randn(2, 1), np.random.randn(1)

X = np.array([[0.5, 0.2]])
y = np.array([1])

Z1, A1, Z2, A2 = forward_pass(X, W1, b1, W2, b2)
print("Output before training:", A2)

W1, b1, W2, b2 = backward_pass(X, y, Z1, A1, Z2, A2, W1, b1, W2, b2)
_, _, _, A2_new = forward_pass(X, W1, b1, W2, b2)

print("Output after one update:", A2_new)
```
### Notes
- This library is for educational purposes.
- Focus is on clarity and simplicity, not speed or production use.
- Requires: numpy, matplotlib